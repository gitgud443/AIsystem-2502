services:
  triton:
    image: nvcr.io/nvidia/tritonserver:25.11-py3
    ports:
      - "8000:8000"
      - "8001:8001"
      - "8002:8002"
    volumes:
      - ./model_repository:/models
    command: >
      tritonserver --model-repository=/models
      --log-verbose=1
      --allow-http=true --allow-grpc=true --allow-metrics=true
    # Uncomment for GPU support (requires NVIDIA Container Toolkit)
    # runtime: nvidia
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]

  fastapi:
    build: .
    ports:
      - "5004:5004"
    volumes:
      - .:/app
    depends_on:
      - triton
    environment:
      - TRITON_URL=http://triton:8000